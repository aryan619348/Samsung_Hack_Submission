{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# &#x2728; Capstone Voice Technology &#x2728;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<b>Idea Name</b> : Proactive assistance model for customer service agents.<br>\n",
    "<b>Members</b>   : <br>\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Name</th>\n",
    "    <th>Email</th>\n",
    "    <th>Branch & Year</th>\n",
    "    <th>Reg. No.</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Aryan S Pillai</td>\n",
    "    <td>aryansantosh.pillai2020@vitstudent.ac.in</td>\n",
    "    <td>CSE with Business Systems, 4th year</td>\n",
    "    <td>20BBS0147</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>Suyash Agarwal</td>\n",
    "    <td>suyash.agarwal2020@vitstudent.ac.in</td>\n",
    "    <td>CSE with Business Systems, 4th year</td>\n",
    "    <td>20BBS0123</td>\n",
    "  </tr>\n",
    "   <tr>\n",
    "    <td>Fenil Thummar</td>\n",
    "    <td>fenil.thummar2020@vitstudent.ac.in</td>\n",
    "    <td>CSE with Business Systems, 4th year</td>\n",
    "    <td>20BBS0032</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<div style=\"display:flex \">\n",
    "    <div style=\"margin: auto auto auto 0\"><h2>Motivation  &#x2b50;</h2>  </div>\n",
    "    <div style=\" margin: auto 0 auto auto \"><b></b></div>\n",
    "</div>\n",
    "<i>Me and my team made this cool thing, a customer service call analyzer. It all started when I got frustrated dealing with a messed-up phone order from Flipkart. Those never-ending calls and no solutions got us thinking—we could use AI to make things better. We wanted to fix not just our own customer service woes but also help others. \n",
    "Our tool looks at how customers act and how the support folks are doing, and it gives personalized solutions. This helps a business keep track of their customer serivce agents much better. It helps find the agents who are performing well and find out techniques that work.\n",
    "They are also able to gauge the customer sentiment and find solutions for them more efficiently.\n",
    "The tool also automates task creation to help the customer and creates personalized emails based on the call and the customers complain reassuring them and helping them give some clearity.\n",
    "We did some research and found out this tool could really change things in the customer service world.\n",
    "\n",
    "The inadequacy of customer service agent training has resulted in a surge of legal cases, compelling companies such as Amazon, Flipkart, and Paytm to address various challenges. Notably, Amazon found itself entangled in a legal dispute in an Assam district court over a non-refundable product worth INR 150. This situation could have been averted through meticulous customer care or the dispatch of a resolution email by the service agent.\n",
    "</i> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<div style=\"display:flex \">\n",
    "    <div style=\"margin: auto auto auto 0\"><h2>Implementation  &#x1f6e0;</h2>  </div>\n",
    "    <div style=\" margin: auto 0 auto auto\"><b></b></div>\n",
    "</div>\n",
    "<i>Breakdown your nitty-gritty project's architechture,features, technologies down here. Provide us with enough details to grasp your technical prowess, but make sure it is snappy and engaging. Flowcharts, Snippets, diagram are your allies here\n",
    "</i> \n",
    "</div>\n",
    "\n",
    "## Complete Flow\n",
    "![img2.png](image2.png)\n",
    "\n",
    "## LLM Flow\n",
    "![img3.png](image3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The flowchart above shows that we are \n",
    "\n",
    "1. using Rag based approach to rate the transcribed calls into good/bad/ moderate\n",
    "\n",
    "\n",
    "2. With the LLMs we can do the following functions\n",
    "    \n",
    "    a. call summary \n",
    "\n",
    "    b. scoring the customer care agent in how did they perform, wheter he was able to solve the problem,etc\n",
    "    \n",
    "    c. Give some advice to the customer care agent on how he can improve\n",
    "    \n",
    "    d. What next steps he can take to help the customers\n",
    "    \n",
    "    e. Automatic mails to the customer can be generated which shows the issues and solutions\n",
    "    \n",
    "    f. easy data analysis on the call, mmultiple calls using chatbot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/speechbox (from -r requirements.txt (line 12))\n",
      "  Cloning https://github.com/huggingface/speechbox to /private/var/folders/n_/kjv34g95635gmdstmh4xrqp00000gn/T/pip-req-build-tq6d2oag\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/speechbox /private/var/folders/n_/kjv34g95635gmdstmh4xrqp00000gn/T/pip-req-build-tq6d2oag\n",
      "  Resolved https://github.com/huggingface/speechbox to commit e7339dc021c8aa3047f824fb5c24b5b2c8197a76\n",
      "  Installing build dependencies ... \u001b[?25l/^C\n",
      "\u001b[?25canceled\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "\n",
    "#huggingface token= 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\n",
    "# OpenAI token = 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"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DEMO LINK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.20.10.3:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n",
      "\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!streamlit run streamlitapp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech To Text\n",
    "\n",
    "For speech to text we explored the whisper models initially but found that speech diarisation that is sperating the speakers is also very imporant and thus we chose the SpeechBox Project to seperate the different speakers in the customer serivce call\n",
    "\n",
    "#### Special Note: \n",
    "1. THE SPEECH TO TEXT HAS ALREADY BEEN PERFOMED AND THE VECTOR-DATABASE HAS BEEN CREATED & SAVED.\n",
    "\n",
    "2. good_call.mp3 = customer service call with good service\n",
    "\n",
    "3. bad_call.mp3 = customer service call with a bad service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For speech to text we can take multiple models like:-\n",
    "1. nvidia/parakeet-tdt-1.1b\n",
    "2. openai/whisper \n",
    "3. facebook/wav2vec2-base-960h\n",
    "\n",
    "We found that Openai/whisper was less resource hungry (we could run it on our cpu) and has the best RTF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Suyash Agarwal\\miniconda3\\Lib\\site-packages\\whisper\\__init__.py:65: UserWarning: C:\\Users\\Suyash Agarwal\\.cache\\whisper\\tiny.en.pt exists, but the SHA256 checksum does not match; re-downloading the file\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████| 72.1M/72.1M [01:15<00:00, 995kiB/s]\n"
     ]
    }
   ],
   "source": [
    "#using whisper\n",
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"tiny.en\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transcribe(\"good_call.mp3\",fp16=False)\n",
    "whisper_transcript= result[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Thank you for calling Quest John. This is Candace. How may I help you? I still have not received my order. You should have able to receive it on the 20th. It's how the 20 second is still nothing. I don't know what's going on, but if it's not too much of a bother to you, I would really, really know the to get what I paid for. You know what I mean? Oh, if it's beyond the promise delivery date, we definitely need to look into that. May have your order number and your full name so I can check for you. That's exactly what I'm thinking. I don't understand what's taking so long. Anyway, the order number is 498, 497 and my name is Tabitha Ratchet. Thank you Tabitha. I will now go ahead and pull up your order. And hopefully I can give you an immediate answer. One moment, please. Go ahead. Thank you. Okay, like what she said, the estimated delivery date is on the 20th. It's not 20 seconds. So it's two days late. Normally when a parcel is late like this, we send an email informing you of the delay. So let me visit the FedEx website and track it. Thank you, Candace. That would be appreciated. I actually haven't tried tracking it on the FedEx website since you already gave me the delivery date through email. So yes, please go ahead. Okay. According to the FedEx note here, your parcel was delivered on the 20th at 10 a.m. It said that it was left on the front porch. Have you tried checking your front porch? What? What? What? What you're kidding, right? Okay. Okay. First of all, my apartment has no front porch. Second, the only way to deliver parcels in a residence is by leaving them to the concierge. Third, I was at home the whole day on the 20th. And no one literally, no one knocked on my door or called my number to notify me of a parcel. So whatever this FedEx guy is saying, his lying. Okay. His lying. That's, that's definitely odd. Have you tried checking with your buildings concierge to see if they have kept a package for you? I just checked this morning and the answer is no. Otherwise, I wouldn't be calling you. Yeah. Your, your neighbors also wouldn't happen to receive it, right? Since, as you said, all parcels go to the concierge. Correct. And if the note says he left it on my doorstep, again, that's impossible. No one can access our doorsteps here except us tenants. So there's clearly a mistake here. Yes, that makes sense. So here's what we're going to do, Tabitha. It is likely that FedEx delivered the order to the wrong address. So I will file a PDNR claim on your behalf. It means parcel delivered, not received. What this does is to let FedEx investigate to find your missing parcel. And after the investigation, we will either refund, replace or find your missing parcel. Okay. Yeah. And for me to initiate the claim, I will send you an email right now. Please reply to that email confirming that you have not received your parcel. Your response to that email is very important because that will serve as the documentation proving to FedEx that you are requesting for us to file a claim on your behalf. Okay. Whatever happens, I'm going to get my refund though, right? Here, right? Of course. And the sooner they find your parcel, the better. By the way, in the event that the parcel isn't recovered, would you prefer a replacement or a refund? I need a replacement for that. I don't want a refund. Okay. I will make note of that. And after the investigation, which usually takes five to seven business days, I will check with the supplier for the availability, availability. And then they can process the replacement for you. Okay. It's disappointing that this is to happen. But okay. Whatever. At least I don't have to file a dispute. To be honest, I was already thinking of calling my bank this morning and filing a dispute. Yes. This is definitely not the experience that we want you to have, but we will try our best to make this as easy as possible for you considering the situation. I will also keep this case in progress. So whatever questions you might have during the investigation, you just reply to the same email thread. And I will be there to answer your questions. So let me get this straight. Seven business days for the investigation. And if it is in found, you're going to check with a team if it's available and if it's available, another seven days to deliver the replacement. Yes, Tabitha, that's correct. But of course, if they find the parcel during the investigation, then you don't need to wait that long. That's already the maximum timeframe. Yeah, well, I hope they do, but I honestly don't have much hope for it, but okay, or a placement's fine, I guess. Okay, yeah, it cannot guarantee that 100% that they would find your missing parcel, but there have been cases in the past when they did find the missing parcel. And I will of course update you throughout the process. Okay, so I guess that's my best option. What do you need me to do? Just reply to your email saying that I didn't receive a parcel. That's correct. I have just sent you the email. All right, I will reply in five minutes. I'm going to have my lunch break. What's your name again? Candice. All right, Candice, thank you so much. That's all I need for now. I have to go. Bye. Enjoy your lunch, Tabitha. Thank you for calling, Quishan. Bye.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisper_transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### For speaker diarization \n",
    "\n",
    "We used a research paper which has implemented it \n",
    "\n",
    "Whisper timeStamped \n",
    "\n",
    "\n",
    "@misc{lintoai2023whispertimestamped,\n",
    "  title={whisper-timestamped},\n",
    "  author={Louradour, J{\\'e}r{\\^o}me},\n",
    "  journal={GitHub repository},\n",
    "  year={2023},\n",
    "  publisher={GitHub},\n",
    "  howpublished = {\\url{https://github.com/linto-ai/whisper-timestamped}}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was giving us promising results \n",
    "##### pros:-\n",
    "1. very fast\n",
    "2. more accurate\n",
    "##### cons:-\n",
    "1. It assumed that every time someone spoke it was a different person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper_timestamped as whistime\n",
    "\n",
    "\n",
    "audio = whistime.load_audio(\"good_call.mp3\")\n",
    "\n",
    "model = whistime.load_model(\"tiny\", device=\"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "result = whistime.transcribe(model, audio, language=\"en\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Came across SpeechBox which was a Hugging face model which included ASR and SpeechDiarization model \n",
    "\n",
    "It was mostly used to transcribe movies, youtube videos,etc. faster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.1.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../.cache/torch/pyannote/models--pyannote--segmentation/snapshots/c4c8ceafcbb3a7a280c2d357aee9fbc9b0be7f9b/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.2.0. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    }
   ],
   "source": [
    "#usign whisper.\n",
    "\n",
    "# You Might be asked to add a Hugging Face Token When running this line of code:\n",
    "# Please use the token: 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\n",
    "\n",
    "import torch\n",
    "from speechbox import ASRDiarizationPipeline\n",
    "import os\n",
    "#change the path to where ur ffmpeg and ffprobe packages are, \n",
    "#for linux use sudo apt install ffmpeg\n",
    "#for macos use brew install ffmpeg\n",
    "os.environ['PATH'] += ':/Users/aryanpillai/capstone/' #change this path to the package path\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "pipeline = ASRDiarizationPipeline.from_pretrained(\"openai/whisper-tiny\", device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript=pipeline(\"good_call.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'speaker': 'SPEAKER_00',\n",
       "  'text': ' You were calling Quaschon, this is Candace, how may I help you?',\n",
       "  'timestamp': (0.0, 4.0)},\n",
       " {'speaker': 'SPEAKER_01',\n",
       "  'text': \" I still have not received my order. You said I would receive it on a 20 if, so the 22nd is still nothing. I don't know what's going on, but if it's not too much of a bother to you, I would really really know to get what I paid for. You know what I mean?\",\n",
       "  'timestamp': (4.0, 20.0)},\n",
       " {'speaker': 'SPEAKER_00',\n",
       "  'text': \" Oh, if it's beyond the promise delivery date, we definitely need to look into that. May have your order number in your full name so I can check for you.\",\n",
       "  'timestamp': (20.0, 27.4)},\n",
       " {'speaker': 'SPEAKER_01',\n",
       "  'text': \" That's exactly what I'm thinking, like I don't understand what's taking so long. Anyway, the order number is 498, 4977,\",\n",
       "  'timestamp': (27.4, 36.24)},\n",
       " {'speaker': 'SPEAKER_00',\n",
       "  'text': \" and my name is Tabitha Ratchid. Thank you, Tabitha. I will now go ahead and pull up your order. And hopefully I can give you an immediate answer. One moment, please. Go ahead, thank you. I will now go ahead and pull up your order and hopefully I can give you an immediate answer. When will it please? Go ahead. Thank you. Okay, like what you said, the estimated delivery date is on the 20th. It's not 20 seconds. So it's two days late. Normally when a person is late like this, we send an email and forming you of the delay. So let me visit the FedEx website and track it.\",\n",
       "  'timestamp': (36.24, 68.0)},\n",
       " {'speaker': 'SPEAKER_01',\n",
       "  'text': ' Thank you, Candice. That would be appreciated. I actually have a try checking it on the FedEx website since you already give me the delivery date through emails. So yes, please go ahead.',\n",
       "  'timestamp': (68.0, 79.0)},\n",
       " {'speaker': 'SPEAKER_00',\n",
       "  'text': ' Okay. According to the FedEx note here, your parcel was delivered on the 20th at 10am. It said that it was left on the front porch. Have you tried checking your front porch?',\n",
       "  'timestamp': (79.0, 92.0)},\n",
       " {'speaker': 'SPEAKER_01',\n",
       "  'text': \" What? What? What? You're kidding, right? Okay. Okay. First of all, my apartment has no front porch. Second, the only way to deliver parcels and arrest the guns is by leaving them to the concierge. Third, I was at home the whole day on the 20th and no one, literally no one knocked on my door or called my number to notify me of a parcel. So whatever this FedEx guy is saying,\",\n",
       "  'timestamp': (92.0, 117.76)},\n",
       " {'speaker': 'SPEAKER_00',\n",
       "  'text': \" his line. Okay, his line. That's this definitely odd. Have you tried checking with your building sconceiers to see if they have kept a package for you?\",\n",
       "  'timestamp': (118.48, 127.48)},\n",
       " {'speaker': 'SPEAKER_01',\n",
       "  'text': \" I just checked this morning and the answer is no. Otherwise, I wouldn't be calling you.\",\n",
       "  'timestamp': (127.48, 131.92)},\n",
       " {'speaker': 'SPEAKER_00',\n",
       "  'text': \" Yeah. Your neighbors also wouldn't happen to receive it, right? Since, as you said, all parcels go to the concierge.\",\n",
       "  'timestamp': (131.92, 139.12)},\n",
       " {'speaker': 'SPEAKER_01',\n",
       "  'text': \" Correct. And if the notes says he left at all my doorstep, again, that's impossible. No one can access our doorsteps here except us 10. So there's clearly a mistake here.\",\n",
       "  'timestamp': (139.12, 148.64)},\n",
       " {'speaker': 'SPEAKER_00',\n",
       "  'text': \" Yes, that makes sense. So here's what we're going to do to have it said. It is lately that FedEx delivered the order to the wrong address. So I will file a PDNR claim on your behalf. It means parcel delivered not received. What this does is to let FedEx investigate to find your missing parcel and after the investigation we will either refund,\",\n",
       "  'timestamp': (149.76, 174.16)},\n",
       " {'speaker': 'SPEAKER_01',\n",
       "  'text': ' replace or find your missing parcel. Okay. Yeah and for me to initiate the claim I will send you an email',\n",
       "  'timestamp': (174.16, 180.72)},\n",
       " {'speaker': 'SPEAKER_00',\n",
       "  'text': ' right now. Please reply to that email confirming that you have not received your parcel. Your response to that email is very important because that will serve as the documentation, proving to FedEx that you are requesting for us to file a claim on your behalf.',\n",
       "  'timestamp': (180.72, 197.6)},\n",
       " {'speaker': 'SPEAKER_01',\n",
       "  'text': \" Okay, whatever happens, I'm gonna get my refund though, right?\",\n",
       "  'timestamp': (197.6, 200.12)},\n",
       " {'speaker': 'SPEAKER_00',\n",
       "  'text': \" You're right, of course. And the sooner they find your parcel, the better. By the way, in the event that the parcel isn't recovered, would you prefer a replacement or a refund? I need to replace\",\n",
       "  'timestamp': (200.12, 211.68)},\n",
       " {'speaker': 'SPEAKER_01',\n",
       "  'text': \" them for that. I don't want to refund. Okay, I will make note of that. And after the investigation\",\n",
       "  'timestamp': (211.68, 219.2)},\n",
       " {'speaker': 'SPEAKER_00',\n",
       "  'text': ' which usually takes five to seven business days, I will check with the supplier for the availability availability and then they can process the replacement for you.',\n",
       "  'timestamp': (219.2, 228.16)},\n",
       " {'speaker': 'SPEAKER_01',\n",
       "  'text': \" Okay, it's disappointing that this is to happen, but okay, whatever, at least I don't have to file a dispute. To be honest, I was already thinking of calling my bank this morning and filing a dispute.\",\n",
       "  'timestamp': (228.16, 241.68)},\n",
       " {'speaker': 'SPEAKER_00',\n",
       "  'text': ' Yes, this definitely not the experience that we want you to have, but we will try our best to make this as easy as possible for you considering the situation. I will also keep this case in progress. So whatever questions you might have during the investigation, you just reply to the same email thread and I will be there to answer your questions.',\n",
       "  'timestamp': (241.68, 263.92)},\n",
       " {'speaker': 'SPEAKER_01',\n",
       "  'text': \" just replied to the same email thread and I will be there to answer your questions. So let me get this straight. Seven business days for the investigation and if it isn't found, you're going to check with a team if it's available and if it's available, another seven days\",\n",
       "  'timestamp': (264.0, 273.76)},\n",
       " {'speaker': 'SPEAKER_00',\n",
       "  'text': \" to deliver the replacement. Yes, Tabitha, that's correct. But of course, if they find the parcel during the investigation, then you don't need to wait that long. That's already the maximum time frame.\",\n",
       "  'timestamp': (273.76, 285.68)},\n",
       " {'speaker': 'SPEAKER_01',\n",
       "  'text': \" Yeah well I hope they do but honestly don't have much hope for it but okay or a placement's fine I guess.\",\n",
       "  'timestamp': (286.72, 293.04)},\n",
       " {'speaker': 'SPEAKER_00',\n",
       "  'text': ' Okay yeah it cannot guarantee that 100% that they would find your missing parcel but there have been cases in the past when they did find the missing parcel and I will of course update you',\n",
       "  'timestamp': (295.28, 307.52)},\n",
       " {'speaker': 'SPEAKER_01',\n",
       "  'text': \" throughout the process. Okay so I guess that's my best option. What do you need me to do? Just reply to your email saying that I didn't receive the parcel? That's correct. I have just sent you the email.\",\n",
       "  'timestamp': (308.24, 319.04)},\n",
       " {'speaker': 'SPEAKER_00',\n",
       "  'text': \" All right I will reply in five minutes. I'm gonna have my lunch break. What's your name again? Candace.\",\n",
       "  'timestamp': (319.76, 324.4)},\n",
       " {'speaker': 'SPEAKER_01',\n",
       "  'text': \" All right Candace thank you so much. That's all I need for now. I have to go. Bye.\",\n",
       "  'timestamp': (325.12, 329.44)},\n",
       " {'speaker': 'SPEAKER_00',\n",
       "  'text': ' Enjoy your lunch Tabitha. Thank you for calling Quiston. Bye.',\n",
       "  'timestamp': (329.44, 332.48)}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"good_call.txt\"\n",
    "\n",
    "# Open the file in write mode\n",
    "with open(file_path, 'w') as file:\n",
    "    # Write each item in the list to the file\n",
    "    for item in transcript:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same thing for the bad_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'speaker': 'SPEAKER_01', 'text': ' Thank you for calling Questron. This is Claire. How may I help you today?', 'timestamp': (0.0, 4.0)}, {'speaker': 'SPEAKER_00', 'text': \" I still have not received my order. You said I would receive it on a 20 if. So the 20 second still nothing. I don't know what's going on, but if it's not too much of a bother to you, I would really really know to get what I paid for. You know what I mean?\", 'timestamp': (4.0, 20.0)}, {'speaker': 'SPEAKER_01', 'text': ' Okay, may have the order number and your first name 498 497', 'timestamp': (20.0, 26.5)}, {'speaker': 'SPEAKER_00', 'text': ' Tabitha Ratchet', 'timestamp': (26.5, 28.5)}, {'speaker': 'SPEAKER_01', 'text': ' Thank you. Let me just check that here', 'timestamp': (29.0, 32.5)}, {'speaker': 'SPEAKER_00', 'text': \" I mean it's ridiculous if there's a delay. You just tell me it's not like you don't have my email or anything You didn't notify me at all if I forgot that I'd ordered it which by the way happens sometimes Then I can completely be paying for nothing.\", 'timestamp': (33.5, 45.16)}, {'speaker': 'SPEAKER_01', 'text': ' One moment please, will I check your order status?', 'timestamp': (45.16, 50.16)}, {'speaker': 'SPEAKER_00', 'text': ' Unbelievable. Are you even listening to me?', 'timestamp': (50.16, 52.96)}, {'speaker': 'SPEAKER_01', 'text': \" I am. That's why I'm going to check this status for you, okay?\", 'timestamp': (52.96, 57.72)}, {'speaker': 'SPEAKER_00', 'text': \" Okay. Fine. Go ahead. Thank you. Let's see.\", 'timestamp': (57.72, 63.72)}, {'speaker': 'SPEAKER_01', 'text': ' Okay. Oh, ha, thank you. You see? Okay. According to the FedEx note here, your parcel was delivered on a 20-year-at-10 AM, and it was left on the front porch according to the notes.', 'timestamp': (63.72, 77.0)}, {'speaker': 'SPEAKER_00', 'text': \" What? You're kidding, right? Okay, okay. First of all, my apartment has no front porch. Second, the only way to build up parcels in a residence is by leaving them to the concierge. That's it. Third, I was at home the whole day on the 20th and no one. Literally no one knocked on my door or called my number to notify me of a parcel. So, whatever this FedEx guy is saying, he's lying. Okay, he's lying.\", 'timestamp': (78.0, 110.8)}, {'speaker': 'SPEAKER_01', 'text': \" Have you tried tracking with the building's concierge to see if they have kept a package for you? Or...\", 'timestamp': (110.8, 116.7)}, {'speaker': 'SPEAKER_00', 'text': \" I just checked this morning and the answer is no! There's the parcel! Otherwise, it wouldn't be calling you!\", 'timestamp': (116.7, 124.0)}, {'speaker': 'SPEAKER_01', 'text': ' How about your neighbors? Have you checked with them to see if they received your parcel?', 'timestamp': (124.0, 128.0)}, {'speaker': 'SPEAKER_00', 'text': ' Just, just, just, just what light of questioning is this? Are you saying that my neighbor stole my partner?', 'timestamp': (128.0, 133.0)}, {'speaker': 'SPEAKER_01', 'text': \" No, no, no, I'm not saying that what I'm saying is, they might have received your parcel while you were away.\", 'timestamp': (133.0, 139.0)}, {'speaker': 'SPEAKER_00', 'text': \" You're not listening to me. I told you it was in the apartment the entire fucking day. If someone delivered a parcel, the concierge would have received it by now. Second, and I repeat, the only way we receive parcels here is through to concierge. Nothing else. No front porch, no neighbors. We're even asking about my neighbors. They have nothing to do with this. And shooting you'll be questioned in the fact that the FedEx said I have a front porch when I clearly don't.\", 'timestamp': (139.0, 161.68)}, {'speaker': 'SPEAKER_01', 'text': \" Tell me that, I'm just doing my job. This is a standard protocol. We have to make sure that the receiver has checked all the possible places the parcel could have been delivered.\", 'timestamp': (162.84, 172.0)}, {'speaker': 'SPEAKER_00', 'text': \" I know. So, do your job right. You're not even trying. I've been spending my time here listening to you and the only thing you're doing so far is asking me dumb questions. Like, what kind of service is this? I just want to get what I paid for. Is that so wrong to ask?\", 'timestamp': (172.0, 185.6)}, {'speaker': 'SPEAKER_01', 'text': \" Please calm down Tabitha. I'm here to help you. Can help me and for God's sake do it well.\", 'timestamp': (186.8, 193.2)}, {'speaker': 'SPEAKER_00', 'text': \" Jesus Christ. Okay Tabitha, I'm sorry that this happened to you. But oh yes I bet you are.\", 'timestamp': (193.2, 200.24)}, {'speaker': 'SPEAKER_01', 'text': ' Okay for us to resolve this I will send you an email. Please reply to that email', 'timestamp': (201.28, 206.24)}, {'speaker': 'SPEAKER_00', 'text': \" to confirm and writing that you did not receive the parcel. After that, I'm getting...\", 'timestamp': (207.28, 212.08)}, {'speaker': 'SPEAKER_01', 'text': \" I'm already talking to you. What do you need me to email you for? I'm not telling you right now.\", 'timestamp': (212.08, 216.08)}, {'speaker': 'SPEAKER_00', 'text': \" I did not receive my parcel. So, do something about it now. It's not that simple,\", 'timestamp': (216.08, 221.04)}, {'speaker': 'SPEAKER_01', 'text': \" Tabith. I have to confirm and writing because that's what we're going to show FedEx so they can begin the investigation. So you know, this is necessary to prove that we are not making this all up. Once the claim is filed, we will investigate and depending on the investigation, it will take seven or seven business days and then we can refund or replace or find your missing parcel.\", 'timestamp': (221.04, 246.08)}, {'speaker': 'SPEAKER_00', 'text': \" So just by the dispute and get my money back, you know that I'm being nice right now, right?\", 'timestamp': (246.08, 251.44)}, {'speaker': 'SPEAKER_01', 'text': \" I am contacting you first when I could just have followed my bank and mark you as fraud in an instant. You know that, right? I wouldn't recommend that as that might poorly reflect on your credit score, especially that it shows delivered. You know? so the best option I recommend is to let us file a claim on your behalf that's what I recommend\", 'timestamp': (251.44, 272.16)}, {'speaker': 'SPEAKER_00', 'text': \" you know what with the ridiculousness of the situation I can't even ring myself to be mad anymore like what is the point anyway you basically have the emotional intelligence of a peanut, so I envy you. That's for sure.\", 'timestamp': (273.12, 285.12)}, {'speaker': 'SPEAKER_01', 'text': ' Okay, so uh, how would you like to proceed?', 'timestamp': (286.56, 289.28)}, {'speaker': 'SPEAKER_00', 'text': \" Huh? It's not like I have a choice. Take care of it. Deal with FedEx. I didn't pay you to make me file the claim myself. So okay, so after you confirm through email that you did not receive\", 'timestamp': (290.56, 302.24)}, {'speaker': 'SPEAKER_01', 'text': ' her parcel, I will file a PDNR for you. What? PDNR. It means parcel delivered not received and it will take five to seven business days.', 'timestamp': (302.24, 313.72)}, {'speaker': 'SPEAKER_00', 'text': \" Okay, what happens if the parcel is that found? Is the replacement available in your warehouse? I need to replace them for that. I don't want to refund.\", 'timestamp': (313.72, 321.28)}, {'speaker': 'SPEAKER_01', 'text': \" Well, since this is a dropship item item we don't have the item in stock in our warehouse so I would first have to check with the dropship team for its availability. But yes I will take note of that. Was it dropship? It means that the item is in another warehouse and we don't have the inventory for it so we will first coordinate with the supplier. You know what, you are making my heads pin.\", 'timestamp': (321.28, 347.24)}, {'speaker': 'SPEAKER_00', 'text': \" So let me get this straight. Seven business days for the investigation and if not found, it should probably be case. Nice and I per cent of the time. You can check with a team if it's available. And then what? Another seven days to deliver the replacement? Yes, correct.\", 'timestamp': (347.24, 363.56)}, {'speaker': 'SPEAKER_01', 'text': \" Mm-hmm. another seven days to deliver the replacement? Yes, correct. I'm going to try to be nice to you guys but it seems like you left me no other choice. I will file a dispute and I will never shop from your site again.\", 'timestamp': (373.2, 377.44)}, {'speaker': 'SPEAKER_00', 'text': ' So as much as I would like to help you, this is the best I can do for you. I have to follow', 'timestamp': (377.44, 382.32)}, {'speaker': 'SPEAKER_01', 'text': ' the company policy. As I said, we can issue replacement you. I have to follow the company policy as I said we can issue a placement But we first have to file a claim and that will take five to seven business days if that is too long for you to wait Which I understand I suggest that you place another order with a different shipping address While the investigation is ongoing and we will just refund you for the first parcel But we first have to wait for the claim', 'timestamp': (382.32, 403.44)}, {'speaker': 'SPEAKER_00', 'text': \" blah blah blah blah Just stop okay. Just stop. I don't care anymore. I hope your company goes bankrupt and the no company will ever hire you again. Your attitude has been pretty disgusting. Condescending the moment you picked up a phone and I cannot, cannot for the life of me imagine and player who would want to hire you for that attitude. Continue living your miserable life. I'm just going to go ahead and file that dispute. Bye-bye.\", 'timestamp': (403.44, 428.92)}]\n"
     ]
    }
   ],
   "source": [
    "transcript_2=pipeline(\"bad_call.mp3\")\n",
    "print(transcript_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"bad_call.txt\"\n",
    "\n",
    "# Open the file in write mode\n",
    "with open(file_path, 'w') as file:\n",
    "    # Write each item in the list to the file\n",
    "    for item in transcript_2:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see that the speech to text is successful and the text file is genrated lets feed this into the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use a RAG based approach since the call conversation is too long currently to dirctly feed into the LLM and hits token limits\n",
    "\n",
    "We use the FAISS vectorDB to store the vectorsore and save it locally so that we dont have to keep creating the embeddings again and again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating vectordatabase for the good call\n",
    "file_path = \"good_call.txt\"\n",
    "loader = TextLoader(file_path)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = FAISS.from_documents(docs, embeddings)\n",
    "db.save_local(\"good_call_diarized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating vectorstore for the bad call\n",
    "file_path = \"bad_call.txt\"\n",
    "loader = TextLoader(file_path)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = FAISS.from_documents(docs, embeddings)\n",
    "db.save_local(\"bad_call_diarized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets experiment with the good call first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create the summary of the good call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Tabitha called Quaschon customer service to inquire about her missing order that was supposed to be delivered on the 20th but had not arrived by the 22nd. Candace, the customer service representative, checked the order and found out that according to FedEx, the parcel was delivered on the 20th at 10 am, left on the front porch. However, Tabitha explained that her apartment did not have a front porch and parcels were usually left with the concierge. Candace suspected that the order was delivered to the wrong address and initiated a PDNR claim on Tabitha's behalf. Tabitha opted for a replacement if the parcel was not found. The investigation would take five to seven business days, and if the parcel was found, the replacement would be processed. Tabitha agreed to reply to the email confirming the non-receipt of the parcel.\n",
      "\n",
      "Problems faced by the customer:\n",
      "1. Missing order that was not delivered on the promised date.\n",
      "2. Parcel was supposedly delivered to the wrong address.\n",
      "3. Inconvenience caused by the delay and misdelivery.\n",
      "\n",
      "Solution:\n",
      "Candace initiated a PDNR claim on Tabitha's behalf to investigate the missing parcel. If the parcel was not found, a replacement would be processed. Tabitha agreed to cooperate by replying to the email confirming the non-receipt of the parcel.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "give a summary of the call, point out the problems the customer is facing, and if a solution was found out\n",
    "{call_text}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "vectorstore= FAISS.load_local(\"good_call_diarized\", OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "retrieval_chain = (\n",
    "    {\"call_text\": retriever}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "answer=retrieval_chain.invoke(\"\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The higlevel call analysis for the good call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    Sentiment: Unsatisfied,\n",
      "    Order_related_query: True,\n",
      "    product related queries: False,\n",
      "    refund related queries: True,\n",
      "    Shipping related queries: True,\n",
      "    solution_found: True,\n",
      "    customer_emotion: Unsatisfied,\n",
      "    agent_emotion_thorughout_the call: Engaged\n",
      "]\n",
      "\n",
      "Explanation: The customer is unsatisfied as they have not received their order and are frustrated with the situation. The call is related to an order issue, specifically a shipping problem. The agent is engaged and actively trying to help the customer by looking into the issue, providing solutions, and initiating a claim for the missing parcel. The customer is unsatisfied with the experience but is somewhat relieved that a solution is being pursued.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "for the below conversation please provide the following criterias\n",
    "[\n",
    "    Sentiment: select the sentiment of the customer,\n",
    "    Order_related_query: True/False,\n",
    "    product related queries: True/False,\n",
    "    refund related queries: True/False,\n",
    "    Shipping related queries: True/False\n",
    "    solution_found: True/False\n",
    "    customer_emotion: Very-Unsatisfied/Unsatisfied/Neutral/Satisfied/Very-Satisfied\n",
    "    agent_emotion_thorughout_the call:Very-Unengaged/Unengaged/Engaged/Positive/Very-Positive\n",
    "]\n",
    "give an explaination\n",
    "{call_text}\n",
    "\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "vectorstore= FAISS.load_local(\"good_call_diarized\", OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "retrieval_chain = (\n",
    "    {\"call_text\": retriever}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "answer=retrieval_chain.invoke(\"\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be a lot more easier to define a function for these operations and use multiple prompt and vector database inputs to create the output so lets do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##function for all the analysis:\n",
    "template = \"\"\"\n",
    "{input_prompt}\n",
    "{call_text}\n",
    "\"\"\"\n",
    "prompt= ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "\n",
    "retrieval_chain = (\n",
    "{\"call_text\": RunnablePassthrough(),\"input_prompt\": RunnablePassthrough()}\n",
    "| prompt\n",
    "| model\n",
    "| StrOutputParser()\n",
    ")\n",
    "\n",
    "#return retrieval_chain.invoke(call_text,input_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the prompts we are using\n",
    "\n",
    "summary_prompt=\"give a summary of the call, point out the problems the customer is facing, and if a solution was found out\"\n",
    "\n",
    "analysis_prompt=\"\"\"\n",
    "for the below conversation please provide the following criterias\n",
    "[\n",
    "    Sentiment: select the sentiment of the customer,\n",
    "    Order_related_query: True/False,\n",
    "    product related queries: True/False,\n",
    "    refund related queries: True/False,\n",
    "    Shipping related queries: True/False\n",
    "    solution_found: True/False\n",
    "    customer_emotion: Very-Unsatisfied/Unsatisfied/Neutral/Satisfied/Very-Satisfied\n",
    "    agent_emotion_thorughout_the call:Very-Unengaged/Unengaged/Engaged/Positive/Very-Positive\n",
    "]\n",
    "give an explaination\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "customer_agent_analysis= \"\"\"\n",
    "Please conduct an analysis of the customer service agent based on the call below measure the following:\n",
    "Communication:\n",
    "Clarity, Tone, Active Listening\n",
    "Knowledge:\n",
    "Product/Service understanding, Accuracy\n",
    "Problem Solving:\n",
    "Effectiveness, Proactive approach\n",
    "Adherence:\n",
    "Follows company policies\n",
    "Time Management:\n",
    "Efficient call handling\n",
    "Empathy:\n",
    "Displays empathy, Customer focus\n",
    "Closure:\n",
    "Ends calls well, Follow-up if needed\n",
    "\n",
    "give them a score out of 10\n",
    "\n",
    "\"\"\"\n",
    "customer_agent_advice=\"\"\"\n",
    "Based on the call below please suggest some ways the customer service agent can improve.\n",
    "make sure you only give suggestions based on the call below and not generic information\n",
    "\"\"\"\n",
    "\n",
    "actions_prompt= \"\"\"\n",
    "    for the given customer interactions create actionable steps that the company will now take help the customer resolve the issue. be professional and use simple language to help them understand the next steps.\n",
    "\"\"\"\n",
    "email_prompt= \"\"\"\n",
    "for the given below conversation create an email draft that will be sent to the customer \n",
    "first give a subject line.\n",
    "then explain the next steps that will be taken to solve their issue.\n",
    "make sure to be professional and sympathetic towards the customer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a good call as it scored an average of 8.8 out of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_text=\"\"\"\n",
    "User Input = Hi. Tell me about yourself.\n",
    "\n",
    "Answer = Hi, I'm here to help and assist you with any questions or feedback you may have about our products. Feel free to reach out to us via Instagram or Whatsapp during our operating hours. Thank you for choosing Snitch, we look forward to assisting you!\n",
    "\n",
    "User Input = Okay, what is.\n",
    "\n",
    "Answer = I'm sorry, but the information provided seems to be related to product images and metadata from a specific source. It does not contain a question or topic to answer. If you have a specific question or topic in mind, please provide it so I can assist you accordingly.\n",
    "\n",
    "User Input = Snetch.\n",
    "\n",
    "Answer = SNITCH offers a variety of products including shirts, jeans, and trousers in different styles and colors suitable for casual and formal wear. Prices range from 999.00 to 1799.00, with options for different sizes. Remember to follow care instructions to maintain the quality of the products.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"industry\": industry, \"job_role\": job_role, \"job_responsibilities\": job_responsibilities, \"painpoints\": painpoints}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "The customer reached out to inquire about the products offered by Snitch. The customer seemed to have trouble articulating their questions or topics, leading to some confusion in the conversation. The customer was provided with information about the products available, including the range of items, styles, colors, and prices. The customer was also reminded to follow care instructions for product maintenance.\n",
      "\n",
      "Problems faced by the customer:\n",
      "- Difficulty in clearly expressing questions or topics\n",
      "- Lack of specific information provided by the customer\n",
      "\n",
      "Solution:\n",
      "The customer was provided with information about the products available at Snitch, addressing their initial query about the brand. The customer was also encouraged to ask specific questions or provide more details for further assistance.\n"
     ]
    }
   ],
   "source": [
    "#customer agent analysis for the good call\n",
    "answer=retrieval_chain.invoke({\"input_prompt\": summary_prompt, \"call_text\": call_text})\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create next steps to take for the agent to help the customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The customer service agent can improve by being more proactive in following up with the customer regarding the status of their order, rather than waiting for the customer to call in with concerns.\n",
      "\n",
      "2. The agent can also improve by providing more detailed information about the next steps in the process, such as the timeline for the investigation and potential outcomes, to manage the customer's expectations more effectively.\n",
      "\n",
      "3. The agent can work on their tone of voice to convey empathy and understanding towards the customer's frustration, which can help build rapport and trust with the customer. \n",
      "\n",
      "4. The agent can improve by offering additional compensation or gestures of goodwill to the customer for the inconvenience caused by the delayed delivery, such as a discount on a future purchase or expedited shipping on the replacement order.\n"
     ]
    }
   ],
   "source": [
    "#advice to the good agent on how to further imrpove\n",
    "answer=analysis(input_prompt=customer_agent_advice,vector_db=\"good_call_diarized\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actionable steps the company will take to help the customer resolve the issue:\n",
      "\n",
      "1. File a PDNR claim on behalf of the customer to investigate the missing parcel.\n",
      "2. Send an email to the customer for confirmation of non-receipt of the parcel to serve as documentation for the claim.\n",
      "3. Offer a refund or replacement for the missing parcel based on customer preference.\n",
      "4. Keep the customer updated on the progress of the investigation and replacement process.\n",
      "5. Respond to any questions or concerns the customer may have during the investigation.\n",
      "6. Follow up with the supplier for availability and process the replacement if needed.\n",
      "7. Provide support and assistance to the customer throughout the resolution process.\n",
      "\n",
      "By following these steps, the company aims to address the customer's issue of the missing parcel and provide a satisfactory resolution.\n"
     ]
    }
   ],
   "source": [
    "#next steps to take for the agent to help the customer\n",
    "answer=analysis(input_prompt=actions_prompt,vector_db=\"good_call_diarized\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on their call we have created custom personalized email to send to the customer for keeping engagement and having easier followups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Resolution of Missing Order Issue - Order Number 4984977\n",
      "\n",
      "Dear Tabitha,\n",
      "\n",
      "I hope this email finds you well. I wanted to follow up on our recent conversation regarding your missing order with order number 4984977.\n",
      "\n",
      "After our discussion, I have initiated a PDNR (Parcel Delivered Not Received) claim with FedEx on your behalf. This claim will prompt FedEx to investigate the delivery discrepancy and locate your missing parcel. \n",
      "\n",
      "I have sent you an email requesting confirmation that you have not received the parcel. Your response to this email is crucial as it will serve as documentation for FedEx during their investigation process.\n",
      "\n",
      "In the event that the parcel is not recovered, you mentioned that you prefer a replacement over a refund. Rest assured, I will keep you updated throughout the investigation process, which typically takes five to seven business days. If a replacement is necessary, I will coordinate with the supplier to ensure a timely delivery.\n",
      "\n",
      "I understand the inconvenience this situation has caused you, and I want to assure you that I am here to assist you every step of the way. Please feel free to reach out to me via email if you have any questions or concerns during the investigation process.\n",
      "\n",
      "Thank you for your patience and cooperation in resolving this matter. Your satisfaction is our top priority, and we will do our best to ensure a positive outcome.\n",
      "\n",
      "Warm regards,\n",
      "\n",
      "Candace\n",
      "Quiston Customer Support Team\n"
     ]
    }
   ],
   "source": [
    "#custom personalized email to send to the customer based on the call\n",
    "answer=analysis(input_prompt=email_prompt,vector_db=\"good_call_diarized\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Lets experiment with the bad call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "The call involves a customer named Tabitha who is frustrated because she has not received her order despite being told it would arrive on a specific date. The customer is upset about the lack of communication regarding the delay and feels that the customer service representative is not listening to her concerns. The customer insists that the parcel was not delivered to her and expresses frustration with the company's handling of the situation. The customer ultimately decides to file a dispute and expresses dissatisfaction with the customer service experience.\n",
      "\n",
      "Problems Faced:\n",
      "1. Customer did not receive the order on the promised date.\n",
      "2. Lack of communication about the delay.\n",
      "3. Customer feels that the delivery information provided by FedEx is inaccurate.\n",
      "4. Customer is frustrated with the customer service representative's questioning and lack of resolution.\n",
      "5. Customer is dissatisfied with the company's process for investigating missing parcels and obtaining replacements.\n",
      "\n",
      "Solution:\n",
      "The customer service representative offers to file a claim on the customer's behalf to investigate the missing parcel. The process involves confirming in writing that the parcel was not received, initiating an investigation that may take seven business days, and potentially issuing a refund or replacement. The customer ultimately decides to file a dispute instead of waiting for the company's investigation process.\n"
     ]
    }
   ],
   "source": [
    "#summary of the call\n",
    "answer=analysis(input_prompt=summary_prompt,vector_db=\"bad_call_diarized\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    Sentiment: Very-Unsatisfied,\n",
      "    Order_related_query: True,\n",
      "    product related queries: False,\n",
      "    refund related queries: True,\n",
      "    Shipping related queries: True,\n",
      "    solution_found: False,\n",
      "    customer_emotion: Very-Unsatisfied,\n",
      "    agent_emotion_thorughout_the call: Unengaged\n",
      "]\n",
      "\n",
      "Explanation:\n",
      "The customer, Tabitha, is very unsatisfied as she has not received her order and is frustrated with the lack of resolution. She is upset about the delay in delivery and feels that the customer service representative is not listening to her concerns. The agent, Claire, seems unengaged throughout the call and fails to provide a satisfactory solution to the customer's issue. The customer is very unsatisfied with the service and threatens to file a dispute and never shop from the site again. The agent's lack of engagement and failure to address the customer's concerns contribute to the overall negative experience for the customer.\n"
     ]
    }
   ],
   "source": [
    "#call analysis\n",
    "answer=analysis(input_prompt=analysis_prompt,vector_db=\"bad_call_diarized\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a good call as it scored an average of 5 out of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the call analysis, here are the scores for the customer service agent:\n",
      "\n",
      "Communication:\n",
      "- Clarity: 6/10\n",
      "- Tone: 4/10\n",
      "- Active Listening: 5/10\n",
      "\n",
      "Knowledge:\n",
      "- Product/Service understanding: 7/10\n",
      "- Accuracy: 6/10\n",
      "\n",
      "Problem Solving:\n",
      "- Effectiveness: 5/10\n",
      "- Proactive approach: 4/10\n",
      "\n",
      "Adherence:\n",
      "- Follows company policies: 6/10\n",
      "\n",
      "Time Management:\n",
      "- Efficient call handling: 5/10\n",
      "\n",
      "Empathy:\n",
      "- Displays empathy: 3/10\n",
      "- Customer focus: 4/10\n",
      "\n",
      "Closure:\n",
      "- Ends calls well: 4/10\n",
      "- Follow-up if needed: 5/10\n",
      "\n",
      "Overall, the customer service agent scored an average of 5/10. There were areas of improvement in communication, empathy, and problem-solving skills. The agent could benefit from enhancing their tone, active listening, empathy, and proactive approach to better assist customers in similar situations.\n"
     ]
    }
   ],
   "source": [
    "#customer agent analysis and scoring\n",
    "answer=analysis(input_prompt=customer_agent_analysis,vector_db=\"bad_call_diarized\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Show empathy and understanding towards the customer's frustration and anger.\n",
      "2. Avoid making statements that could be perceived as condescending or dismissive.\n",
      "3. Offer solutions or alternatives proactively instead of waiting for the customer to suggest them.\n",
      "4. Provide clear and concise explanations of company policies and procedures without overwhelming the customer with unnecessary details.\n",
      "5. Maintain a calm and professional tone throughout the conversation, even in the face of customer hostility.\n",
      "6. Acknowledge the customer's concerns and validate their feelings before moving on to problem-solving.\n",
      "7. Avoid engaging in arguments or defending company policies when the customer is upset, focus on finding a resolution instead.\n"
     ]
    }
   ],
   "source": [
    "# how cutomer service agent can improve\n",
    "answer=analysis(input_prompt=customer_agent_advice,vector_db=\"bad_call_diarized\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actionable steps for the company to help the customer resolve the issue:\n",
      "\n",
      "1. Send an email to the customer for them to confirm in writing that they did not receive the parcel.\n",
      "2. File a PDNR (Parcel Delivered Not Received) claim on behalf of the customer, which will take five to seven business days.\n",
      "3. Check with the drop ship team for the availability of a replacement item, as the item is not in stock in the company's warehouse.\n",
      "4. Inform the customer that if the parcel is not found, the replacement process may take an additional seven days.\n",
      "5. Advise the customer to consider placing another order with a different shipping address while the investigation is ongoing, and the company will refund the first parcel once the claim is processed.\n",
      "6. Maintain professionalism and empathy in all interactions with the customer, even in challenging situations.\n",
      "\n",
      "By following these steps, the company can work towards resolving the customer's issue and providing a satisfactory outcome.\n"
     ]
    }
   ],
   "source": [
    "#next actionable steps to\n",
    "answer=analysis(input_prompt=actions_prompt,vector_db=\"bad_call_diarized\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Resolution of Your Order Issue\n",
      "\n",
      "Dear Tabitha Ratchett,\n",
      "\n",
      "I hope this email finds you well. I am writing to address the concerns you raised regarding the non-receipt of your order. I understand your frustration and I sincerely apologize for the inconvenience this has caused you.\n",
      "\n",
      "After our conversation, I will be initiating the process to file a claim with FedEx on your behalf. This will involve sending you an email to confirm in writing that you did not receive the parcel. Once this confirmation is received, we will proceed with the investigation, which may take up to seven business days. Depending on the outcome of the investigation, we will either refund your payment or arrange for a replacement of the missing parcel.\n",
      "\n",
      "I want to assure you that I am committed to resolving this issue for you as efficiently as possible. Your satisfaction is important to us, and we will do everything we can to make this right for you.\n",
      "\n",
      "Please be on the lookout for the email with instructions on confirming the non-receipt of your parcel. If you have any further questions or concerns, please do not hesitate to reach out to me directly.\n",
      "\n",
      "Thank you for your understanding and patience in this matter.\n",
      "\n",
      "Warm regards,\n",
      "\n",
      "Claire\n",
      "Customer Service Representative\n"
     ]
    }
   ],
   "source": [
    "#custom personalized email for the customer\n",
    "answer=analysis(input_prompt=email_prompt,vector_db=\"bad_call_diarized\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets checkout the chatbot implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the good calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The customer's problem is that they have not received their order, even though the estimated delivery date was on the 20th and it is now the 22nd. The customer is concerned about not receiving what they paid for and suspects that there may have been a mistake in the delivery process.\n"
     ]
    }
   ],
   "source": [
    "template_2 = \"\"\"\n",
    "answer the question using the call script below\n",
    "{call_text}\n",
    "\n",
    "Question = {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template_2)\n",
    "\n",
    "retrieval_chain_2 = (\n",
    "    {\"call_text\": retriever,\"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "answer=retrieval_chain_2.invoke( \"what is the customers problem?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the call script provided, the agent, Candace, appears to be polite and helpful to the customer, Tabitha. Candace listens to Tabitha's concerns, investigates the issue with the missing parcel, explains the process of filing a claim, and offers solutions such as a refund or replacement. Candace also assures Tabitha that she will keep her updated throughout the process and provides clear instructions on how to proceed. Overall, Candace demonstrates professionalism and courtesy in handling the customer's issue.\n"
     ]
    }
   ],
   "source": [
    "answer=retrieval_chain_2.invoke( \"is my agent polite to this customer?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the call script provided, the customer, Tabitha, seemed satisfied by the end of the call. Despite the initial frustration of not receiving her order, Candace from Quiston was able to assist Tabitha in filing a PDNR claim with FedEx to investigate the missing parcel. Tabitha expressed understanding of the process and was grateful for the assistance provided. She even thanked Candace and mentioned that she had to go, indicating a resolution to the issue. Therefore, it can be inferred that the customer was happy by the end of the call.\n"
     ]
    }
   ],
   "source": [
    "answer=retrieval_chain_2.invoke( \"was the customer hjappy by the end of the call\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets create a fuunciton for the chatbot too so that its easier to call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##function for chatbot:\n",
    "def chatbot(question, vector_db):\n",
    "    template= \"\"\"\n",
    "    answer the Question = {question}  \n",
    "    using the call script below\n",
    "    {call_text}\n",
    "    \"\"\"\n",
    "    prompt= ChatPromptTemplate.from_template(template)\n",
    "    model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "    vectorstore= FAISS.load_local(vector_db, OpenAIEmbeddings())\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    retrieval_chain = (\n",
    "    {\"call_text\": retriever,\"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    return retrieval_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The customer's pain point is that they have not received their order, despite being told it would arrive on a specific date. They are frustrated with the lack of communication and the inconvenience of not receiving what they paid for. They feel that the company is not taking their concerns seriously and is not providing satisfactory solutions to the issue.\n"
     ]
    }
   ],
   "source": [
    "answer = chatbot(\"what is the customers painpoint?\",vector_db=\"bad_call_diarized\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <div style=\"display:flex;\">\n",
    "        <div style=\"margin: auto auto auto 0;\">\n",
    "            <h2>Future Work Proposal  &#x1f680;</h2>\n",
    "        </div>\n",
    "        <div style=\"margin: auto 0 auto auto;\">\n",
    "            <b></b>\n",
    "        </div>\n",
    "    </div>\n",
    "    <i>This tool has huge potential, and there are some things that we would like to improve:</i>\n",
    "    <ol>\n",
    "        <li>\n",
    "            <b>Have the ability to handle multiple audio files and sources at the same time:</b>\n",
    "            <p>The companies have huge data of customer calls, and we want this tool to be able to handle a large amount of files and provide company-wide analysis.</p>\n",
    "        </li>\n",
    "        <li>\n",
    "            <b>Make Proper dashboards:</b>\n",
    "            <p>Make company-wide dashboards that help identify the products that are having the most issues and even create dashboards for each agent from all their calls to analyze and help find inefficient agents.</p>\n",
    "        </li>\n",
    "        <li>\n",
    "            <b>Integration with platforms like Gmail, SMS, and WhatsApp:</b>\n",
    "            <p>We are currently creating steps that the agent should take to solve customer issues based on the call and can even create personalized emails. It will be cool to have an integration with Gmail, SMS, and Whatsapp to directly communicate with customers with AI in an automated fashion.</p>\n",
    "        </li>\n",
    "        <li>\n",
    "            <b>Completely automated AI agent call:</b>\n",
    "            <p>With the current GenAI implementation with proper hardware resources, it's possible to have a human-like conversation, and we know that an AI agent will be 24*7 available and won't have the misbehavior of a tired customer support human agent.</p>\n",
    "        </li>\n",
    "    </ol>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the prompts we are using\n",
    "\n",
    "summary_prompt=\"\"\"give a summary of the call, point out the problems the customer is facing, and if a solution was found out. give the output in this json format only:\n",
    "{\n",
    "    Summary:\n",
    "    ProblemsFacedByCustomer:\n",
    "    SolutionFound:\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "analysis_prompt=\"\"\"\n",
    "for the below conversation please provide the following criterias\n",
    "[\n",
    "    Sentiment: select the sentiment of the customer,\n",
    "    Order_related_query: True/False,\n",
    "    product related queries: True/False,\n",
    "    refund related queries: True/False,\n",
    "    Shipping related queries: True/False\n",
    "    solution_found: True/False\n",
    "    customer_emotion: Very-Unsatisfied/Unsatisfied/Neutral/Satisfied/Very-Satisfied\n",
    "    agent_emotion_thorughout_the call:Very-Unengaged/Unengaged/Engaged/Positive/Very-Positive\n",
    "]\n",
    "give an explaination\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "customer_agent_analysis= \"\"\"\n",
    "Please conduct an analysis of the customer service agent based on the call below measure the following and give out put in JSON format, give them a score out of 10:\n",
    "{\n",
    "    Communication:\n",
    "        Clarity, Tone, Active Listening\n",
    "    Knowledge:\n",
    "        Product/Service understanding, Accuracy\n",
    "    Problem Solving:\n",
    "        Effectiveness, Proactive approach\n",
    "    Adherence:\n",
    "        Follows company policies\n",
    "    Empathy:\n",
    "        Displays empathy, Customer focus\n",
    "    Closure:\n",
    "        Ends calls well, Follow-up if needed\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "customer_agent_advice=\"\"\"\n",
    "Based on the call below please suggest some ways the customer service agent can improve.\n",
    "make sure you only give suggestions based on the call below and not generic information\n",
    "\n",
    "Give the output in JSON format\n",
    "{\n",
    "    CustomerAgentAdvice: \n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "steps_prompt= \"\"\"\n",
    "    for the given customer interactions create actionable steps that the company will now take help the customer resolve the issue. be professional and use simple language to help them understand the next steps.\n",
    "    Give output in JSON format:\n",
    "    {\n",
    "        NextSteps:\n",
    "    }\n",
    "\"\"\"\n",
    "email_prompt= \"\"\"\n",
    "for the given below conversation create an email draft that will be sent to the customer \n",
    "first give a subject line.\n",
    "then explain the next steps that will be taken to solve their issue.\n",
    "make sure to be professional and sympathetic towards the customer.\n",
    "Give output in JSON format:\n",
    "    {\n",
    "        Email:\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##function for all the analysis:\n",
    "template = \"\"\"\n",
    "{input_prompt}\n",
    "{call_text}\n",
    "\"\"\"\n",
    "prompt= ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "\n",
    "retrieval_chain = (\n",
    "{\"call_text\": RunnablePassthrough(),\"input_prompt\": RunnablePassthrough()}\n",
    "| prompt\n",
    "| model\n",
    "| StrOutputParser()\n",
    ")\n",
    "\n",
    "#return retrieval_chain.invoke(call_text,input_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_text=\"\"\"\n",
    "User Input = Hi. Tell me about yourself.\n",
    "\n",
    "Answer = Hi, I'm here to help and assist you with any questions or feedback you may have about our products. Feel free to reach out to us via Instagram or Whatsapp during our operating hours. Thank you for choosing Snitch, we look forward to assisting you!\n",
    "\n",
    "User Input = Okay, what is.\n",
    "\n",
    "Answer = I'm sorry, but the information provided seems to be related to product images and metadata from a specific source. It does not contain a question or topic to answer. If you have a specific question or topic in mind, please provide it so I can assist you accordingly.\n",
    "\n",
    "User Input = Snetch.\n",
    "\n",
    "Answer = SNITCH offers a variety of products including shirts, jeans, and trousers in different styles and colors suitable for casual and formal wear. Prices range from 999.00 to 1799.00, with options for different sizes. Remember to follow care instructions to maintain the quality of the products.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from call_process_templates import summary_prompt, analysis_prompt, customer_agent_analysis,customer_agent_advice,steps_prompt,email_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Summary\": \"The customer reached out to inquire about the products offered by Snitch and requested information about the company.\",\n",
      "    \"ProblemsFacedByCustomer\": \"The customer did not provide a specific question or topic for the agent to address, leading to a lack of clarity in the conversation.\",\n",
      "    \"SolutionFound\": \"The agent provided general information about the products offered by Snitch and reminded the customer to follow care instructions for product maintenance.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#customer agent analysis for the good call\n",
    "answer1=retrieval_chain.invoke({\"input_prompt\": summary_prompt, \"call_text\": call_text})\n",
    "print(answer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor the below conversation please provide the following criterias as True/Fasle and mention make sure to answer all the below:\\n{\\n    \"Sentiment\": \"\",\\n    \"Order_related_query\": \"\",\\n    \"Product_related_queries\": \"\",\\n    \"Refund_related_queries\": \"\",\\n    \"Shipping_related_queries\": \"\",\\n    \"Solution_found\": \"\",\\n    \"Customer_emotion\": \"\",\\n    \"Agent_emotion_throughout_the_call\": \"\"\\n}\\nmake sure that the output is in JSON format\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Sentiment\": \"\",\n",
      "    \"Order_related_query\": false,\n",
      "    \"Product_related_queries\": true,\n",
      "    \"Refund_related_queries\": false,\n",
      "    \"Shipping_related_queries\": false,\n",
      "    \"Solution_found\": true,\n",
      "    \"Customer_emotion\": \"\",\n",
      "    \"Agent_emotion_throughout_the_call\": \"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#customer agent analysis for the good call\n",
    "answer2=retrieval_chain.invoke({\"input_prompt\": analysis_prompt, \"call_text\": call_text})\n",
    "print(answer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Communication\": {\n",
      "        \"Clarity\": 8,\n",
      "        \"Tone\": 9,\n",
      "        \"Active Listening\": 7\n",
      "    },\n",
      "    \"Knowledge\": {\n",
      "        \"Product/Service understanding\": 9,\n",
      "        \"Accuracy\": 8\n",
      "    },\n",
      "    \"Problem Solving\": {\n",
      "        \"Effectiveness\": 7,\n",
      "        \"Proactive approach\": 6\n",
      "    },\n",
      "    \"Adherence\": 8,\n",
      "    \"Empathy\": {\n",
      "        \"Displays empathy\": 9,\n",
      "        \"Customer focus\": 8\n",
      "    },\n",
      "    \"Closure\": {\n",
      "        \"Ends calls well\": 8,\n",
      "        \"Follow-up if needed\": 7\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#customer agent analysis for the good call\n",
    "answer3=retrieval_chain.invoke({\"input_prompt\": customer_agent_analysis, \"call_text\": call_text})\n",
    "print(answer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"CustomerAgentAdvice\": \"The customer service agent can improve by actively listening to the customer's queries and providing more specific and detailed responses. They should also ensure they understand the customer's questions before responding to avoid confusion. Additionally, the agent can offer to provide more information or clarification if the customer seems unsure or confused about the products or services.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#customer agent analysis for the good call\n",
    "answer4=retrieval_chain.invoke({\"input_prompt\": customer_agent_advice, \"call_text\": call_text})\n",
    "print(answer4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"NextSteps\": \"1. If you have any questions or feedback about our products, feel free to reach out to us via Instagram or Whatsapp during our operating hours.\\n2. If you have a specific question or topic in mind, please provide it so we can assist you accordingly.\\n3. Remember to follow care instructions to maintain the quality of the products you purchase from SNITCH.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#customer agent analysis for the good call\n",
    "answer5=retrieval_chain.invoke({\"input_prompt\": steps_prompt, \"call_text\": call_text})\n",
    "print(answer5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"SubjectLine\": \"Assistance with SNITCH Products\",\n",
      "    \"Email\": \"Dear Customer,\\n\\nThank you for reaching out to us with your questions about SNITCH products. We appreciate your interest in our brand.\\n\\nBased on our conversation, it seems like you are looking for more information about the products we offer, specifically shirts, jeans, and trousers in various styles and colors. Our prices range from 999.00 to 1799.00, with options for different sizes.\\n\\nTo assist you further, we recommend visiting our website or contacting our customer service team for any specific queries or assistance you may need. We are here to help and ensure you have a pleasant shopping experience with SNITCH.\\n\\nPlease feel free to reach out to us via Instagram or Whatsapp during our operating hours. We value your feedback and look forward to serving you.\\n\\nThank you for choosing SNITCH.\\n\\nBest regards,\\n[Your Name]\\nCustomer Service Team\\nSNITCH\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#customer agent analysis for the good call\n",
    "answer6=retrieval_chain.invoke({\"input_prompt\": email_prompt, \"call_text\": call_text})\n",
    "print(answer6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "js_obj_1=json.loads(answer1)\n",
    "js_obj_2=json.loads(answer2)\n",
    "js_obj_3=json.loads(answer3)\n",
    "js_obj_4=json.loads(answer4)\n",
    "js_obj_5=json.loads(answer5)\n",
    "js_obj_6=json.loads(answer6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Summary': 'The customer reached out to inquire about the products offered by Snitch and requested information about the company.', 'ProblemsFacedByCustomer': 'The customer did not provide a specific question or topic for the agent to address, leading to a lack of clarity in the conversation.', 'SolutionFound': 'The agent provided general information about the products offered by Snitch and reminded the customer to follow care instructions for product maintenance.'}\n"
     ]
    }
   ],
   "source": [
    "print(js_obj_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(js_obj_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Summary\": \"The customer reached out to inquire about the products offered by Snitch and requested information about the company.\", \"ProblemsFacedByCustomer\": \"The customer did not provide a specific question or topic for the agent to address, leading to a lack of clarity in the conversation.\", \"SolutionFound\": \"The agent provided general information about the products offered by Snitch and reminded the customer to follow care instructions for product maintenance.\", \"Sentiment\": \"\", \"Order_related_query\": false, \"Product_related_queries\": true, \"Refund_related_queries\": false, \"Shipping_related_queries\": false, \"Solution_found\": true, \"Customer_emotion\": \"\", \"Agent_emotion_throughout_the_call\": \"\", \"Communication\": {\"Clarity\": 8, \"Tone\": 9, \"Active Listening\": 7}, \"Knowledge\": {\"Product/Service understanding\": 9, \"Accuracy\": 8}, \"Problem Solving\": {\"Effectiveness\": 7, \"Proactive approach\": 6}, \"Adherence\": 8, \"Empathy\": {\"Displays empathy\": 9, \"Customer focus\": 8}, \"Closure\": {\"Ends calls well\": 8, \"Follow-up if needed\": 7}, \"CustomerAgentAdvice\": \"The customer service agent can improve by actively listening to the customer's queries and providing more specific and detailed responses. They should also ensure they understand the customer's questions before responding to avoid confusion. Additionally, the agent can offer to provide more information or clarification if the customer seems unsure or confused about the products or services.\", \"NextSteps\": \"1. If you have any questions or feedback about our products, feel free to reach out to us via Instagram or Whatsapp during our operating hours.\\n2. If you have a specific question or topic in mind, please provide it so we can assist you accordingly.\\n3. Remember to follow care instructions to maintain the quality of the products you purchase from SNITCH.\", \"SubjectLine\": \"Assistance with SNITCH Products\", \"Email\": \"Dear Customer,\\n\\nThank you for reaching out to us with your questions about SNITCH products. We appreciate your interest in our brand.\\n\\nBased on our conversation, it seems like you are looking for more information about the products we offer, specifically shirts, jeans, and trousers in various styles and colors. Our prices range from 999.00 to 1799.00, with options for different sizes.\\n\\nTo assist you further, we recommend visiting our website or contacting our customer service team for any specific queries or assistance you may need. We are here to help and ensure you have a pleasant shopping experience with SNITCH.\\n\\nPlease feel free to reach out to us via Instagram or Whatsapp during our operating hours. We value your feedback and look forward to serving you.\\n\\nThank you for choosing SNITCH.\\n\\nBest regards,\\n[Your Name]\\nCustomer Service Team\\nSNITCH\"}\n"
     ]
    }
   ],
   "source": [
    "# Create a new dictionary to store combined objects\n",
    "combined_obj = {}\n",
    "\n",
    "# Merge the contents of each JSON object into the combined dictionary\n",
    "combined_obj.update(js_obj_1)\n",
    "combined_obj.update(js_obj_2)\n",
    "combined_obj.update(js_obj_3)\n",
    "combined_obj.update(js_obj_4)\n",
    "combined_obj.update(js_obj_5)\n",
    "combined_obj.update(js_obj_6)\n",
    "\n",
    "# Convert the combined dictionary back to JSON format\n",
    "combined_json = json.dumps(combined_obj)\n",
    "\n",
    "# Print or use the combined JSON object\n",
    "print(combined_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"output_audio.ulaw\", \"wb\").close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samsung_hack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
